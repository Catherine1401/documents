{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CepRKCw-s1lr"
      },
      "outputs": [],
      "source": [
        "# TASK 1\n",
        "# 1. Import th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 2. ƒê·ªãnh nghƒ©a t√™n file\n",
        "filename = \"50_Startups.csv\"\n",
        "\n",
        "# 3. Ki·ªÉm tra n·∫øu file ch∆∞a t·ªìn t·∫°i th√¨ y√™u c·∫ßu t·∫£i l√™n\n",
        "if not os.path.exists(filename):\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    filename = list(uploaded.keys())[0]  # L·∫•y t√™n file v·ª´a t·∫£i l√™n\n",
        "\n",
        "# 4. ƒê·ªçc file CSV v√†o DataFrame\n",
        "df = pd.read_csv(filename)\n",
        "\n",
        "# 5. Lo·∫°i b·ªè c√°c c·ªôt ch·ª©a d·ªØ li·ªáu kh√¥ng ph·∫£i s·ªë\n",
        "df_numeric = df.select_dtypes(include=[np.number])  # Ch·ªâ gi·ªØ l·∫°i c√°c c·ªôt s·ªë\n",
        "\n",
        "# 6. Hi·ªÉn th·ªã 5 d√≤ng ƒë·∫ßu ti√™n ƒë·ªÉ ki·ªÉm tra d·ªØ li·ªáu\n",
        "print(\"\\nüìå D·ªØ li·ªáu s·ªë ban ƒë·∫ßu:\")\n",
        "print(df_numeric.head())\n",
        "\n",
        "# 7. T√≠nh to√°n c√°c th·ªëng k√™ c∆° b·∫£n\n",
        "summary = df_numeric.describe()\n",
        "print(\"\\nüìå Th·ªëng k√™ d·ªØ li·ªáu:\\n\", summary)\n",
        "\n",
        "# 8. V·∫Ω scatter plot gi·ªØa t·ª´ng feature v√† bi·∫øn ph·ª• thu·ªôc y\n",
        "y = df_numeric.iloc[:, -1]  # C·ªôt cu·ªëi c√πng l√† bi·∫øn ph·ª• thu·ªôc (y)\n",
        "features = df_numeric.columns[:-1]  # C√°c c·ªôt c√≤n l·∫°i l√† feature\n",
        "\n",
        "for feature in features:\n",
        "    plt.scatter(df_numeric[feature], y)\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel(\"Output (y)\")\n",
        "    plt.title(f'Scatter plot: {feature} vs Output')\n",
        "    plt.show()\n",
        "\n",
        "# 9. V·∫Ω histogram c·ªßa t·ª´ng feature\n",
        "for feature in df_numeric.columns:\n",
        "    mean = df_numeric[feature].mean()\n",
        "    var = df_numeric[feature].var()\n",
        "    plt.hist(df_numeric[feature], bins=20, alpha=0.7, color='blue')\n",
        "    plt.title(f'Histogram of {feature} (mean={mean:.1f}, var={var:.1f})')\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.show()\n",
        "\n",
        "# 10. T√≠nh h·ªá s·ªë t∆∞∆°ng quan gi·ªØa c√°c bi·∫øn\n",
        "correlations = df_numeric.corr()\n",
        "print(\"\\nüìå H·ªá s·ªë t∆∞∆°ng quan gi·ªØa y v√† c√°c feature:\")\n",
        "print(correlations.iloc[-1, :-1])  # In h·ªá s·ªë t∆∞∆°ng quan c·ªßa y v·ªõi c√°c feature\n",
        "\n",
        "# 11. Chu·∫©n h√≥a d·ªØ li·ªáu\n",
        "# a. Minmax scaling (ƒë∆∞a d·ªØ li·ªáu v·ªÅ kho·∫£ng [0,1])\n",
        "X_minmax = (df_numeric.iloc[:, :-1] - df_numeric.iloc[:, :-1].min()) / (df_numeric.iloc[:, :-1].max() - df_numeric.iloc[:, :-1].min())\n",
        "\n",
        "# b. Standardization (chu·∫©n h√≥a sao cho mean=0, variance=1)\n",
        "X_standardized = (df_numeric.iloc[:, :-1] - df_numeric.iloc[:, :-1].mean()) / df_numeric.iloc[:, :-1].std()\n",
        "\n",
        "# 12. Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu th√†nh X1 (min=1, max=10)\n",
        "X1 = df_numeric.iloc[:, :-1].apply(lambda x: 1 + 9 * (x - x.min()) / (x.max() - x.min()))\n",
        "\n",
        "# 13. Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu th√†nh X2 b·∫±ng chu·∫©n h√≥a (standardize)\n",
        "X2 = X_standardized.copy()\n",
        "\n",
        "# 14. In k·∫øt qu·∫£ ƒë·ªÉ ki·ªÉm tra\n",
        "print(\"\\nüìå D·ªØ li·ªáu sau MinMax Scaling:\\n\", X_minmax.head())\n",
        "print(\"\\nüìå D·ªØ li·ªáu sau Standardization:\\n\", X_standardized.head())\n",
        "print(\"\\nüìå D·ªØ li·ªáu sau chuy·ªÉn ƒë·ªïi th√†nh X1:\\n\", X1.head())\n",
        "print(\"\\nüìå D·ªØ li·ªáu sau chu·∫©n h√≥a th√†nh X2:\\n\", X2.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hADTkcxvtCN"
      },
      "outputs": [],
      "source": [
        "# TASK 2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# 1Ô∏è‚É£ ƒê·ªçc d·ªØ li·ªáu t·ª´ file (gi·ªØ l·∫°i c√°c c·ªôt c·∫ßn thi·∫øt)\n",
        "df = pd.read_csv(\"50_Startups.csv\")\n",
        "df_numeric = df.select_dtypes(include=[np.number])  # Ch·ªâ l·∫•y c·ªôt s·ªë\n",
        "\n",
        "# 2Ô∏è‚É£ X√°c ƒë·ªãnh X1 (c√°c feature) v√† y1 (profit)\n",
        "X1 = df_numeric[['R&D Spend', 'Administration', 'Marketing Spend']].values  # Chuy·ªÉn th√†nh m·∫£ng numpy\n",
        "y1 = df_numeric['Profit'].values.reshape(-1, 1)  # Chuy·ªÉn th√†nh vector c·ªôt\n",
        "\n",
        "# 3Ô∏è‚É£ Chu·∫©n h√≥a d·ªØ li·ªáu X1 (Standardization)\n",
        "X1 = (X1 - np.mean(X1, axis=0)) / np.std(X1, axis=0)\n",
        "\n",
        "# 4Ô∏è‚É£ Th√™m c·ªôt bias (1) v√†o X1 ƒë·ªÉ t√≠nh to√°n b d·ªÖ d√†ng h∆°n\n",
        "X1 = np.c_[X1, np.ones(X1.shape[0])]\n",
        "\n",
        "# 5Ô∏è‚É£ H√†m t√≠nh Loss Function L(a, b) (Mean Squared Error)\n",
        "def compute_loss(y_hat, y):\n",
        "    m = len(y)\n",
        "    return np.sum((y_hat - y) ** 2) / (2 * m)\n",
        "\n",
        "# 6Ô∏è‚É£ Gradient Descent ƒë·ªÉ t√¨m a1, a2, a3, b\n",
        "def gradient_descent(X, y, alpha=0.01, iterations=1000):\n",
        "    m, n = X.shape\n",
        "    theta = np.zeros((n, 1))  # Kh·ªüi t·∫°o h·ªá s·ªë a1, a2, a3, b\n",
        "    loss_history = []\n",
        "\n",
        "    for i in range(iterations):\n",
        "        y_hat = X @ theta  # T√≠nh gi√° tr·ªã d·ª± ƒëo√°n\n",
        "        gradient = (X.T @ (y_hat - y)) / m  # Gradient c·ªßa Loss function\n",
        "        theta -= alpha * gradient  # C·∫≠p nh·∫≠t h·ªá s·ªë\n",
        "        loss_history.append(compute_loss(y_hat, y))  # L∆∞u loss v√†o history\n",
        "\n",
        "    return theta, loss_history\n",
        "\n",
        "# 7Ô∏è‚É£ Ch·∫°y gradient descent ƒë·ªÉ t√¨m a1, a2, a3, b\n",
        "theta_optimal, loss_history = gradient_descent(X1, y1, alpha=0.01, iterations=500)\n",
        "\n",
        "# 8Ô∏è‚É£ V·∫Ω ƒë·ªì th·ªã loss function theo s·ªë b∆∞·ªõc l·∫∑p\n",
        "plt.plot(range(len(loss_history)), loss_history, color='red')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss function over iterations')\n",
        "plt.show()\n",
        "\n",
        "# 9Ô∏è‚É£ T√≠nh gi√° tr·ªã d·ª± ƒëo√°n y_hat\n",
        "y_hat = X1 @ theta_optimal\n",
        "\n",
        "# üîü V·∫Ω scatter plot gi·ªØa y_hat v√† y th·ª±c t·∫ø\n",
        "plt.scatter(y1, y_hat, alpha=0.7)\n",
        "plt.xlabel(\"Actual Profit (y)\")\n",
        "plt.ylabel(\"Predicted Profit (y_hat)\")\n",
        "plt.title(\"Predicted Profit vs Actual Profit\")\n",
        "plt.show()\n",
        "\n",
        "# 1Ô∏è‚É£1Ô∏è‚É£ ƒê√°nh gi√° ƒë·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh b·∫±ng RMSE, MAE, R¬≤\n",
        "rmse = np.sqrt(mean_squared_error(y1, y_hat))\n",
        "mae = mean_absolute_error(y1, y_hat)\n",
        "r2 = r2_score(y1, y_hat)\n",
        "\n",
        "print(f\"üìå RMSE: {rmse:.2f}\")\n",
        "print(f\"üìå MAE: {mae:.2f}\")\n",
        "print(f\"üìå R¬≤ Score: {r2:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
